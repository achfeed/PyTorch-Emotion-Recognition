{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Deep_Learning_Emotion_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PVCHxi2ASuCZ",
        "6bNrOA7mSuCe",
        "pSVMbuVJSuC-",
        "nGWDE42iSuDQ",
        "xjZ0GXI9SuDX",
        "avHYthQdSuDi",
        "Yo6GVV87SuDk",
        "xTLKA47iSuDz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achfeed/PyTorch-Emotion-Recognition/blob/main/PyTorch_Deep_Learning_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StfRpRW1SuBw"
      },
      "source": [
        "# Deep Learning Based Emotion Recognition with PyTorch\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/emotion_classifier.png?raw=true)\n",
        "\n",
        "In this notebook we are going to learn how to train deep neural networks, such as recurrent neural networks (RNNs), for addressing a natural language task known as **emotion recognition**. We will cover everything you need to know to get started with NLP using deep learning frameworks such as TensorFlow. We will cover the common best practices, functionalities, and steps you need to understand the basics of TensorFlow APIs to build powerful predictive models via the computation graph. In the process of building our models, we will compare PyTorch and TensorFlow to let the learner appreciate the strenghts of each tool.\n",
        "\n",
        "by [Elvis Saravia](https://twitter.com/omarsar0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIkM141cSuBz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrz3-nSrSuB1"
      },
      "source": [
        "## Outline\n",
        "1. Deep Learning Frameworks\n",
        "     - 1.1 Eager execution\n",
        "     - 1.2 Computation graph\n",
        "2. Tensors\n",
        "    - 2.1 Basic math with tensors\n",
        "    - 2.2 Transforming tensors\n",
        "3. Data\n",
        "    - 3.1 Preprocessing data\n",
        "        - Tokenization and Sampling\n",
        "        - Constructing Vocabulary and Index-Word Mapping\n",
        "    - 3.2 Converting data into tensors\n",
        "    - 3.3 Padding data\n",
        "    - 3.4 Binarization\n",
        "    - 3.5 Split data\n",
        "    - 3.6 Data Loader\n",
        "4. Model\n",
        "    - 4.1 Pretesting Model\n",
        "    - 4.2 Testing models with eager execution\n",
        "5. Training\n",
        "6. Evaluation on Testing Dataset\n",
        "    - 6.1 Confusion matrix\n",
        "- Final Words\n",
        "- References\n",
        "- *Storing models and setting checkpoints (Exercise)*\n",
        "- *Restoring models (Exercise)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy9JWaqqSuB1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCbWgC0tSuB3"
      },
      "source": [
        "## 1. Deep Learning Frameworks\n",
        "There are many deep learning frameworks such as Chainer, DyNet, MXNet, PyTorch, TensorFlow, and Keras. Each framework has their own strenghts which a researcher or a developer may want to consider before choosing the right framework. In my opinion, PyTorch is great for researchers and offers eager execution by default, but its high-level APIs require some understanding of deep learning concepts such as **affine layers** and **automatic differentiation**. On the other hand, TensorFlow was originally built as a low-level API that provides a robust list of functionalities to build deep learning models from the ground up. More recently, TensorFlow also offers **eager execution** and is equipped with a high-level API known as Keras.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/dl_frameworks.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suv8DnrQSuB5"
      },
      "source": [
        "### 1.1 Eager Execution\n",
        "Eager execution allows us to operate on the computation graph dynamically, also known as **imperative programming**. TensorFlow requires that you manually set this mode, while PyTorch comes with this mode by default. Below we import the necessary libraries to use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CURzvVldMJcU",
        "outputId": "3f2cf279-8d34-48ae-b060-f1580a7fd6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "!pip uninstall torch\n",
        "\n",
        "!pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.1-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torch-0.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch-0.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-0.4.1\n",
            "Collecting torch==0.4.1\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu90/torch-0.4.1-cp36-cp36m-linux_x86_64.whl (519.5MB)\n",
            "\u001b[K     |███▋                            | 59.3MB 82.4MB/s eta 0:00:06y\n",
            "\u001b[K     |█████████████▎                  | 215.3MB 79.6MB/s eta 0:00:04achraf\n",
            "\u001b[K     |█████████████████████▉          | 353.8MB 83.3MB/s eta 0:00:02hurry\n",
            "\u001b[K     |████████████████████████████████| 519.5MB 93.2MB/s \n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "hurry\n",
            "come on google\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnUazzVHSuB6"
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK69ztCKSuB-"
      },
      "source": [
        "### 1.2 Computation Graph\n",
        "A simplified definition of a neural network is a string of functions that are **differentiable** and that we can combine together to get more complicated functions. An intuitive way to express this process is through computation graphs. \n",
        "\n",
        "![alt txt](http://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png)\n",
        "\n",
        "Image credit: [Chris Olah](http://colah.github.io/posts/2015-08-Backprop/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6243JBwQSuB_"
      },
      "source": [
        "## 2. Tensors\n",
        "Tensors are the fundamental data structure used to store data that will be fed as input to a computation graph for processing and applying tranformations. Let's create two tensors and multiply them, and then output the result. The figure below shows a 4-D Tensor.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/tensor.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q72g6eRGSuCA",
        "outputId": "d98efc74-1991-4c31-d42e-a55e60e1a282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "c = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "d = torch.tensor([[1.0, 1.0], [0.0, 1.0]])\n",
        "e = torch.matmul(c, d)\n",
        "print(e)\n",
        "print(c.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 3.],\n",
            "        [3., 7.]])\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTM0Y6hSuCF"
      },
      "source": [
        "### 2.1 Math with Tensors\n",
        "PyTorch and other deep learning libraries like TensorFlow allow you to do **automatic differentation**. Let's try to compute the derivative of a function -- in this case that function is stored in the variable `z`. In PyTorch, the option `requires_grad=True` tracks all operations applied to the input tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855r1t0MSuCG",
        "outputId": "3946ad2e-68bc-41bb-d5e4-26f978108062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "### Automatic differentiation with PyTorch\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "\n",
        "# an operation of tensor\n",
        "y = x + 2 # y inherits grad_fn\n",
        "\n",
        "# apply operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(out)\n",
        "\n",
        "out.backward()\n",
        "\n",
        "print(x.grad) # d(out)/dx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(27., grad_fn=<MeanBackward1>)\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwHvtrCLSuCK"
      },
      "source": [
        "You can verfiy the output with the equations in the figure below:\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/autograd.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6j5_2wFSuCL"
      },
      "source": [
        "### 2.2 Transforming Tensors\n",
        "We can also apply some transformation to a tensor such as adding a dimension or transposing it. Let's try both adding a dimension and transposing a matrix below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT8u_3rzSuCL",
        "outputId": "4c31dd25-88ef-434f-8245-7a7138ddc411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"X shape: \", x.size())\n",
        "\n",
        "# add dimension\n",
        "print(x.unsqueeze(1).size()) \n",
        "\n",
        "# transpose \n",
        "torch.transpose(x, 0,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:  torch.Size([2, 3])\n",
            "torch.Size([2, 1, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggtl1m6aSuCP"
      },
      "source": [
        "## 3. Emotion Dataset\n",
        "In this notebook we are working on an emotion classification task. The dataset contains tweets labeled into 6 categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JqoUiTSuCP"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1UAm-Hm2dRk"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgQ3FjAM2dVo"
      },
      "source": [
        "link = 'https://drive.google.com/open?id=1xMTON4HFXvGZ9iHsC44XI2QNKybq4wTL'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyb-YbPa2dZe",
        "outputId": "7774fa57-3c16-47d7-ffdc-32fa4b46af22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1xMTON4HFXvGZ9iHsC44XI2QNKybq4wTL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DwjQfDi2dNc"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('tweets_combined.csv')  \n",
        "data = pd.read_csv('tweets_combined.csv')# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2sYWY79SuCS",
        "outputId": "38193b9d-2069-4b00-8c5e-2b145a968b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "ax = data.target.value_counts().plot.bar(color = ['red', 'black'])\n",
        "for p in ax.patches:\n",
        "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNSP0G-SuCV"
      },
      "source": [
        "data.drop(columns=['Unnamed: 0'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVSdPNTA_iZh",
        "outputId": "bd6d7b4d-9dde-42fe-a819-6768d0575dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Today in Selfcare: beauty &amp;amp; laughs Kung Fu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I get to spend New Year's home again alone and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Depressed and lonely /: Stuck in a deep, never...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If this is your response to someone saying the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Apparently you get a free pass just by mention...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  target\n",
              "0  Today in Selfcare: beauty &amp; laughs Kung Fu...       0\n",
              "1  I get to spend New Year's home again alone and...       1\n",
              "2  Depressed and lonely /: Stuck in a deep, never...       1\n",
              "3  If this is your response to someone saying the...       0\n",
              "4  Apparently you get a free pass just by mention...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nI00TmkSuCY"
      },
      "source": [
        "### 3.1 Preprocessing Data\n",
        "In the next steps we are going to create tokenize the text, create index mapping for words, and also construct a vocabulary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCHxi2ASuCZ"
      },
      "source": [
        "#### Tokenization and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYDgIXGGSuCb"
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"tweet\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 6].copy()\n",
        "\n",
        "# sampling\n",
        "data = data.sample(n=3200, replace=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bNrOA7mSuCe"
      },
      "source": [
        "#### Constructing Vocabulary and Index-Word Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KouYEDoNSuCe"
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFasv0ASuCi",
        "outputId": "c530341d-65d1-40c0-b171-15e1f0d06579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"tweet\"].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '#Grind',\n",
              " '#Hustle',\n",
              " '#NAME?',\n",
              " '#blissful',\n",
              " '#delicious',\n",
              " '#fury',\n",
              " '#getHelp',\n",
              " '#happy',\n",
              " '#joyful']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqf0tC3FSuCk"
      },
      "source": [
        "### 3.2 Converting Data into Tensors \n",
        "For convenience we would like to convert the data into tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omlfNU8hSuCk"
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"tweet\"].values.tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AphKgs33SuCn",
        "outputId": "29ef5445-d79d-4680-eb1b-d907fe340098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[66, 81], [48, 132, 1, 3, 2]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzoIfZHjSuCr"
      },
      "source": [
        "### 3.3 Padding data\n",
        "In order to train our recurrent neural network later on in the notebook, it is required padding to generate inputs of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbSHvs0SuCs"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zyXKoy6SuCw",
        "outputId": "51b63625-8911-4733-c70b-15d9b194b839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYk71VEPSuC0"
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wKDdBCSuC2"
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dok2XcWSuC7",
        "outputId": "afce5839-c8f1-4af1-b681-7d2a11cfca73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([66, 81,  0,  0,  0]), array([ 48, 132,   1,   3,   2])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-"
      },
      "source": [
        "### 3.4 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBN6xAsGSuDA"
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.target.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['target']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_369xrpSuDC",
        "outputId": "5d93df6f-862c-4ed7-eeb3-dbd32e890d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "target_tensor[0:2] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLZMnNbUSuDF",
        "outputId": "f5beda03-94e6-4666-e175-d35e82f69af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "data[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>target</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>Tue blues</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>967</th>\n",
              "      <td>Grind smarter.  #Hustle #Grind</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              tweet  target  token_size\n",
              "766                       Tue blues       0           2\n",
              "967  Grind smarter.  #Hustle #Grind       0           5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCgbz5icSuDI"
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bI6rF59SuDK",
        "outputId": "803c22a5-50f5-41dc-8471-d69de2f1aca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxi-STseSuDN"
      },
      "source": [
        "emotion_dict = {0: 'neutral', 1: 'depressed'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRkO7WISuDN",
        "outputId": "949dba0d-4af6-4434-c41f-f9fe90a171f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neutral'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWDE42iSuDQ"
      },
      "source": [
        "### 3.5 Split data\n",
        "We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQuGQReSuDR",
        "outputId": "f5eef107-e274-4af5-dbac-a88cdd86aab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2560, 2560, 320, 320, 320, 320)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ0GXI9SuDX"
      },
      "source": [
        "### 3.6 Data Loader\n",
        "We can also laod the data into a data loader, which makes it easy to **manipulate the data**, **create batches**, and apply further **transformations**. In PyTorch we can use the `DataLoader` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0xtwf8nSuDX"
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMDa8eJVSuDY"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0Of7YiSuDa"
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgVVs1XSuDc"
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQNqg9xSuDe",
        "outputId": "30a101fd-6934-4e59-a55b-4d56a0f5007b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "val_dataset.batch_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqYHyFGwSuDh"
      },
      "source": [
        "## 4. Model\n",
        "After the data has been preprocessed, transformed and prepared it is now time to construct the model or the so-called computation graph that will be used to train our classification models. We are going to use a gated recurrent neural network (GRU), which is considered a more efficient version of a basic RNN. The figure below shows a high-level overview of the model details. \n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/gru-model.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHYthQdSuDi"
      },
      "source": [
        "### 4.1 Constructing the Model\n",
        "Below we construct our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVXtMhf3SuDj"
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6GVV87SuDk"
      },
      "source": [
        "### 4.2 Pretesting model\n",
        "Since eager execution is enabled we can print the output of the model by passing a sample of the dataset and making sure that the dimensions of the outputs are the expected ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjomHaHbSuDl"
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhymNqRSuDn",
        "outputId": "641b9e04-87af-4d1e-cd0c-ee936d08a1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "# model.to(device)\n",
        "model.cuda()\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "# output, _ = model(xs.to(device), lens, device)\n",
        "output, _ = model(xs.cuda(), lens, 'cuda')\n",
        "\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([5, 64])\n",
            "torch.Size([64, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRXfA2NSuDp"
      },
      "source": [
        "## 5. Training the Model\n",
        "Now that we have tested the model, it is time to train it. We will define out optimization algorithm, learnin rate, and other necessary information to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFuDTsrUSuDp"
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "# model.to(device)\n",
        "model.cuda()\n",
        "\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyvsSQrPSuDr",
        "outputId": "7a559f5b-35b8-4d9e-800c-5cc17ca489d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "trn_loss = []\n",
        "vld_loss = []\n",
        "trn_accuracy = [] \n",
        "vld_accuracy = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    val_total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    trn_loss.append(total_loss / TRAIN_N_BATCH)\n",
        "    trn_accuracy.append(train_accuracy / TRAIN_N_BATCH)\n",
        "\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):\n",
        "        loss = 0\n",
        "\n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)\n",
        "\n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        val_total_loss += batch_loss\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "\n",
        "    vld_loss.append(val_total_loss / VAL_N_BATCH)\n",
        "\n",
        "    vld_accuracy.append(val_accuracy / VAL_N_BATCH)\n",
        "\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.3556\n",
            "Epoch 1 Loss 0.0273 -- Train Acc. 97.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.3554832935333252 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.0000\n",
            "Epoch 2 Loss 0.0000 -- Train Acc. 100.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.33849596977233887 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.0000\n",
            "Epoch 3 Loss 0.0000 -- Train Acc. 100.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.3326106071472168 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.0000\n",
            "Epoch 4 Loss 0.0000 -- Train Acc. 100.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.3402750492095947 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.0000\n",
            "Epoch 5 Loss 0.0000 -- Train Acc. 100.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.3472881317138672 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.0000\n",
            "Epoch 6 Loss 0.0000 -- Train Acc. 100.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.34036755561828613 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.0000\n",
            "Epoch 7 Loss 0.0000 -- Train Acc. 100.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.3296537399291992 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.0000\n",
            "Epoch 8 Loss 0.0000 -- Train Acc. 100.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.33784055709838867 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.0000\n",
            "Epoch 9 Loss 0.0000 -- Train Acc. 100.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.3266723155975342 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.0000\n",
            "Epoch 10 Loss 0.0000 -- Train Acc. 100.0000 -- Val Acc. 100.0000\n",
            "Time taken for 1 epoch 0.33617162704467773 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72jYWoxDSuDt",
        "outputId": "bc86cd79-34ce-4cea-a59c-5da72110924b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(169, 256)\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ckUBn9K0GvC"
      },
      "source": [
        "## 5 - Bis / Varying the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smEN_Nvc0E1H",
        "outputId": "f6b8d26a-d452-4343-936a-11ffb1d28f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "# model.to(device)\n",
        "model.cuda()\n",
        "\n",
        "lr_list = [1e-8, 1e-7, 1e-6, 1e-5, 1e-3,3e-3,1e-2]\n",
        "trn_loss = []\n",
        "vld_loss = []\n",
        "\n",
        "for lr in lr_list:\n",
        "\n",
        "  ### loss criterion and optimizer for training\n",
        "  criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "  def loss_function(y, prediction):\n",
        "      \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "      # convert from one-hot encoding to class indices\n",
        "      target = torch.max(y, 1)[1]\n",
        "      loss = criterion(prediction, target) \n",
        "      return loss   #TODO: refer the parameter of these functions as the same\n",
        "      \n",
        "  def accuracy(target, logit):\n",
        "      ''' Obtain accuracy for training round '''\n",
        "      target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "      corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "      accuracy = 100.0 * corrects / len(logit)\n",
        "      return accuracy\n",
        "\n",
        "  EPOCHS = 1\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "      start = time.time()\n",
        "      \n",
        "      ### Initialize hidden state\n",
        "      # TODO: do initialization here.\n",
        "      total_loss = 0\n",
        "      val_total_loss = 0\n",
        "      train_accuracy, val_accuracy = 0, 0\n",
        "      \n",
        "      ### Training\n",
        "      for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "          loss = 0\n",
        "          predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "                \n",
        "          loss += loss_function(targ.to(device), predictions)\n",
        "          batch_loss = (loss / int(targ.shape[1]))        \n",
        "          total_loss += batch_loss\n",
        "          \n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "          train_accuracy += batch_accuracy\n",
        "\n",
        "          \n",
        "          if batch % 100 == 0:\n",
        "              print('Lr {} Epoch {} Batch {} Val. Loss {:.4f}'.format(lr, epoch + 1,\n",
        "                                                          batch,\n",
        "                                                          batch_loss.cpu().detach().numpy()))\n",
        "              \n",
        "      ### Validating\n",
        "      for (batch, (inp, targ, lens)) in enumerate(val_dataset):\n",
        "          loss = 0\n",
        "\n",
        "          predictions,_ = model(inp.permute(1, 0).to(device), lens, device)\n",
        "\n",
        "          loss += loss_function(targ.to(device), predictions)\n",
        "          batch_loss = (loss / int(targ.shape[1]))        \n",
        "          val_total_loss += batch_loss\n",
        "\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "          val_accuracy += batch_accuracy\n",
        "      \n",
        "      print('Lr {} Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(lr, epoch + 1, \n",
        "                                                              total_loss / TRAIN_N_BATCH, \n",
        "                                                              train_accuracy / TRAIN_N_BATCH,\n",
        "                                                              val_accuracy / VAL_N_BATCH))\n",
        "      print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "      trn_loss.append(total_loss / TRAIN_N_BATCH)\n",
        "      vld_loss.append(val_total_loss / VAL_N_BATCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lr 1e-08 Epoch 1 Batch 0 Val. Loss 0.3066\n",
            "Lr 1e-08 Epoch 1 Batch 100 Val. Loss 0.2940\n",
            "Lr 1e-08 Epoch 1 Batch 200 Val. Loss 0.3055\n",
            "Lr 1e-08 Epoch 1 Batch 300 Val. Loss 0.3044\n",
            "Lr 1e-08 Epoch 1 Batch 400 Val. Loss 0.3011\n",
            "Lr 1e-08 Epoch 1 Batch 500 Val. Loss 0.3091\n",
            "Lr 1e-08 Epoch 1 Batch 600 Val. Loss 0.3015\n",
            "Lr 1e-08 Epoch 1 Loss 0.3029 -- Train Acc. 14.0150 -- Val Acc. 14.4431\n",
            "Time taken for 1 epoch 26.645325422286987 sec\n",
            "\n",
            "Lr 1e-07 Epoch 1 Batch 0 Val. Loss 0.3059\n",
            "Lr 1e-07 Epoch 1 Batch 100 Val. Loss 0.3062\n",
            "Lr 1e-07 Epoch 1 Batch 200 Val. Loss 0.3045\n",
            "Lr 1e-07 Epoch 1 Batch 300 Val. Loss 0.2921\n",
            "Lr 1e-07 Epoch 1 Batch 400 Val. Loss 0.3051\n",
            "Lr 1e-07 Epoch 1 Batch 500 Val. Loss 0.2974\n",
            "Lr 1e-07 Epoch 1 Batch 600 Val. Loss 0.2885\n",
            "Lr 1e-07 Epoch 1 Loss 0.2961 -- Train Acc. 16.1950 -- Val Acc. 20.4327\n",
            "Time taken for 1 epoch 27.02806329727173 sec\n",
            "\n",
            "Lr 1e-06 Epoch 1 Batch 0 Val. Loss 0.2905\n",
            "Lr 1e-06 Epoch 1 Batch 100 Val. Loss 0.2682\n",
            "Lr 1e-06 Epoch 1 Batch 200 Val. Loss 0.2669\n",
            "Lr 1e-06 Epoch 1 Batch 300 Val. Loss 0.2561\n",
            "Lr 1e-06 Epoch 1 Batch 400 Val. Loss 0.2615\n",
            "Lr 1e-06 Epoch 1 Batch 500 Val. Loss 0.2595\n",
            "Lr 1e-06 Epoch 1 Batch 600 Val. Loss 0.2657\n",
            "Lr 1e-06 Epoch 1 Loss 0.2700 -- Train Acc. 31.9325 -- Val Acc. 33.0929\n",
            "Time taken for 1 epoch 26.385777711868286 sec\n",
            "\n",
            "Lr 1e-05 Epoch 1 Batch 0 Val. Loss 0.2624\n",
            "Lr 1e-05 Epoch 1 Batch 100 Val. Loss 0.2714\n",
            "Lr 1e-05 Epoch 1 Batch 200 Val. Loss 0.2624\n",
            "Lr 1e-05 Epoch 1 Batch 300 Val. Loss 0.2572\n",
            "Lr 1e-05 Epoch 1 Batch 400 Val. Loss 0.2846\n",
            "Lr 1e-05 Epoch 1 Batch 500 Val. Loss 0.2597\n",
            "Lr 1e-05 Epoch 1 Batch 600 Val. Loss 0.2750\n",
            "Lr 1e-05 Epoch 1 Loss 0.2644 -- Train Acc. 32.5000 -- Val Acc. 33.4936\n",
            "Time taken for 1 epoch 26.432074785232544 sec\n",
            "\n",
            "Lr 0.001 Epoch 1 Batch 0 Val. Loss 0.2571\n",
            "Lr 0.001 Epoch 1 Batch 100 Val. Loss 0.2711\n",
            "Lr 0.001 Epoch 1 Batch 200 Val. Loss 0.2109\n",
            "Lr 0.001 Epoch 1 Batch 300 Val. Loss 0.1016\n",
            "Lr 0.001 Epoch 1 Batch 400 Val. Loss 0.0785\n",
            "Lr 0.001 Epoch 1 Batch 500 Val. Loss 0.0372\n",
            "Lr 0.001 Epoch 1 Batch 600 Val. Loss 0.0348\n",
            "Lr 0.001 Epoch 1 Loss 0.1430 -- Train Acc. 67.1575 -- Val Acc. 92.4479\n",
            "Time taken for 1 epoch 26.74498176574707 sec\n",
            "\n",
            "Lr 0.003 Epoch 1 Batch 0 Val. Loss 0.0324\n",
            "Lr 0.003 Epoch 1 Batch 100 Val. Loss 0.0196\n",
            "Lr 0.003 Epoch 1 Batch 200 Val. Loss 0.0402\n",
            "Lr 0.003 Epoch 1 Batch 300 Val. Loss 0.0075\n",
            "Lr 0.003 Epoch 1 Batch 400 Val. Loss 0.0939\n",
            "Lr 0.003 Epoch 1 Batch 500 Val. Loss 0.0299\n",
            "Lr 0.003 Epoch 1 Batch 600 Val. Loss 0.0457\n",
            "Lr 0.003 Epoch 1 Loss 0.0403 -- Train Acc. 91.9175 -- Val Acc. 93.1891\n",
            "Time taken for 1 epoch 26.78397274017334 sec\n",
            "\n",
            "Lr 0.01 Epoch 1 Batch 0 Val. Loss 0.0289\n",
            "Lr 0.01 Epoch 1 Batch 100 Val. Loss 0.0908\n",
            "Lr 0.01 Epoch 1 Batch 200 Val. Loss 0.2803\n",
            "Lr 0.01 Epoch 1 Batch 300 Val. Loss 0.3032\n",
            "Lr 0.01 Epoch 1 Batch 400 Val. Loss 0.5089\n",
            "Lr 0.01 Epoch 1 Batch 500 Val. Loss 0.3278\n",
            "Lr 0.01 Epoch 1 Batch 600 Val. Loss 0.2592\n",
            "Lr 0.01 Epoch 1 Loss 0.2765 -- Train Acc. 61.0975 -- Val Acc. 54.9679\n",
            "Time taken for 1 epoch 26.19807195663452 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5GCb8Xd0FUJ",
        "outputId": "cdfdffdf-85e3-4fe5-f70d-6c387b2fb1f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "fig = plt.figure(figsize = (14,8))\n",
        "plt.plot(lr_list, vld_loss, label = 'validation loss')\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title('Finding the optimal learning rate')\n",
        "fig.savefig('lr_find.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0YAAAHwCAYAAACCKH9ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABAyvt/WD1lxhOtLMQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DO-gbC_-nHO"
      },
      "source": [
        "## 5 ters - Uisng the optimal learning rate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nm07St5-nlJ",
        "outputId": "97163770-1eec-48d4-fec9-083839af4239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "# model.to(device)\n",
        "model.cuda()\n",
        "\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-3)\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "trn_loss = []\n",
        "vld_loss = []\n",
        "trn_accuracy = [] \n",
        "vld_accuracy = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    val_total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    trn_loss.append(total_loss / TRAIN_N_BATCH)\n",
        "    trn_accuracy.append(train_accuracy / TRAIN_N_BATCH)\n",
        "\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):\n",
        "        loss = 0\n",
        "\n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)\n",
        "\n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        val_total_loss += batch_loss\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "\n",
        "    vld_loss.append(val_total_loss / VAL_N_BATCH)\n",
        "\n",
        "    vld_accuracy.append(val_accuracy / VAL_N_BATCH)\n",
        "\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.2957\n",
            "Epoch 1 Batch 100 Val. Loss 0.2700\n",
            "Epoch 1 Batch 200 Val. Loss 0.1001\n",
            "Epoch 1 Batch 300 Val. Loss 0.0445\n",
            "Epoch 1 Batch 400 Val. Loss 0.0452\n",
            "Epoch 1 Batch 500 Val. Loss 0.0323\n",
            "Epoch 1 Batch 600 Val. Loss 0.0292\n",
            "Epoch 1 Loss 0.1063 -- Train Acc. 76.3750 -- Val Acc. 92.4880\n",
            "Time taken for 1 epoch 25.049155473709106 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.0159\n",
            "Epoch 2 Batch 100 Val. Loss 0.0302\n",
            "Epoch 2 Batch 200 Val. Loss 0.0160\n",
            "Epoch 2 Batch 300 Val. Loss 0.0316\n",
            "Epoch 2 Batch 400 Val. Loss 0.0095\n",
            "Epoch 2 Batch 500 Val. Loss 0.0360\n",
            "Epoch 2 Batch 600 Val. Loss 0.0307\n",
            "Epoch 2 Loss 0.0303 -- Train Acc. 93.3250 -- Val Acc. 94.1106\n",
            "Time taken for 1 epoch 25.584909439086914 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.0260\n",
            "Epoch 3 Batch 100 Val. Loss 0.0233\n",
            "Epoch 3 Batch 200 Val. Loss 0.0305\n",
            "Epoch 3 Batch 300 Val. Loss 0.0132\n",
            "Epoch 3 Batch 400 Val. Loss 0.0466\n",
            "Epoch 3 Batch 500 Val. Loss 0.0668\n",
            "Epoch 3 Batch 600 Val. Loss 0.0401\n",
            "Epoch 3 Loss 0.0328 -- Train Acc. 93.4325 -- Val Acc. 93.1290\n",
            "Time taken for 1 epoch 26.11691689491272 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.0237\n",
            "Epoch 4 Batch 100 Val. Loss 0.0689\n",
            "Epoch 4 Batch 200 Val. Loss 0.0578\n",
            "Epoch 4 Batch 300 Val. Loss 0.0622\n",
            "Epoch 4 Batch 400 Val. Loss 0.0399\n",
            "Epoch 4 Batch 500 Val. Loss 0.0632\n",
            "Epoch 4 Batch 600 Val. Loss 0.0485\n",
            "Epoch 4 Loss 0.0542 -- Train Acc. 90.0300 -- Val Acc. 86.8790\n",
            "Time taken for 1 epoch 26.40581727027893 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.0833\n",
            "Epoch 5 Batch 100 Val. Loss 0.0530\n",
            "Epoch 5 Batch 200 Val. Loss 0.0628\n",
            "Epoch 5 Batch 300 Val. Loss 0.0315\n",
            "Epoch 5 Batch 400 Val. Loss 0.0370\n",
            "Epoch 5 Batch 500 Val. Loss 0.0232\n",
            "Epoch 5 Batch 600 Val. Loss 0.0604\n",
            "Epoch 5 Loss 0.0693 -- Train Acc. 87.9650 -- Val Acc. 90.8454\n",
            "Time taken for 1 epoch 26.33356475830078 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.0361\n",
            "Epoch 6 Batch 100 Val. Loss 0.0636\n",
            "Epoch 6 Batch 200 Val. Loss 0.1542\n",
            "Epoch 6 Batch 300 Val. Loss 0.1389\n",
            "Epoch 6 Batch 400 Val. Loss 0.0970\n",
            "Epoch 6 Batch 500 Val. Loss 0.1105\n",
            "Epoch 6 Batch 600 Val. Loss 0.0980\n",
            "Epoch 6 Loss 0.1124 -- Train Acc. 79.4000 -- Val Acc. 78.8061\n",
            "Time taken for 1 epoch 26.126834630966187 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.1235\n",
            "Epoch 7 Batch 100 Val. Loss 0.1317\n",
            "Epoch 7 Batch 200 Val. Loss 0.0872\n",
            "Epoch 7 Batch 300 Val. Loss 0.1298\n",
            "Epoch 7 Batch 400 Val. Loss 0.1429\n",
            "Epoch 7 Batch 500 Val. Loss 0.1254\n",
            "Epoch 7 Batch 600 Val. Loss 0.1511\n",
            "Epoch 7 Loss 0.1301 -- Train Acc. 75.8525 -- Val Acc. 60.6571\n",
            "Time taken for 1 epoch 26.085268259048462 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.2266\n",
            "Epoch 8 Batch 100 Val. Loss 0.2205\n",
            "Epoch 8 Batch 200 Val. Loss 0.1934\n",
            "Epoch 8 Batch 300 Val. Loss 0.2150\n",
            "Epoch 8 Batch 400 Val. Loss 0.1325\n",
            "Epoch 8 Batch 500 Val. Loss 0.1776\n",
            "Epoch 8 Batch 600 Val. Loss 0.2217\n",
            "Epoch 8 Loss 0.1932 -- Train Acc. 62.9175 -- Val Acc. 61.8590\n",
            "Time taken for 1 epoch 26.1072359085083 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.1990\n",
            "Epoch 9 Batch 100 Val. Loss 0.2221\n",
            "Epoch 9 Batch 200 Val. Loss 0.1789\n",
            "Epoch 9 Batch 300 Val. Loss 0.1619\n",
            "Epoch 9 Batch 400 Val. Loss 0.1933\n",
            "Epoch 9 Batch 500 Val. Loss 0.1668\n",
            "Epoch 9 Batch 600 Val. Loss 0.2054\n",
            "Epoch 9 Loss 0.1890 -- Train Acc. 62.2175 -- Val Acc. 60.2163\n",
            "Time taken for 1 epoch 26.115335702896118 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.2014\n",
            "Epoch 10 Batch 100 Val. Loss 0.2338\n",
            "Epoch 10 Batch 200 Val. Loss 0.2168\n",
            "Epoch 10 Batch 300 Val. Loss 0.1972\n",
            "Epoch 10 Batch 400 Val. Loss 0.2048\n",
            "Epoch 10 Batch 500 Val. Loss 0.2373\n",
            "Epoch 10 Batch 600 Val. Loss 0.2586\n",
            "Epoch 10 Loss 0.2022 -- Train Acc. 59.3200 -- Val Acc. 57.6322\n",
            "Time taken for 1 epoch 26.17516827583313 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKiF3LKuSuDu"
      },
      "source": [
        "## 6. Evaluation on the Testing Data\n",
        "Now we will evaluate the model with the holdout dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-IORQgwSuDv",
        "outputId": "1288a226-7a80-449c-cac5-b10f39e15495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "device = \"cuda\" # we don't need GPU to do testing\n",
        "model.to(\"cuda\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  92.08974358974359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTLKA47iSuDz"
      },
      "source": [
        "### 6.1 Confusion Matrix\n",
        "The test accuracy alone is not an interesting performance metric in this case. Let's plot a confusion matrix to get a drilled down view of how the model is performing with regards to each emotion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM9g0v7sRTTM"
      },
      "source": [
        "### Class to Properly Evaluate our Models\n",
        "class Evaluate():\n",
        "\n",
        "    def va_dist(cls, prediction, target, va_df, binarizer, name='', silent=False):\n",
        "        \"\"\" Computes distance between actual and prediction through cosine distance \"\"\"\n",
        "        va_matrix = va_df.loc[binarizer.classes_][['valence','arousal']].values\n",
        "        y_va = target.dot(va_matrix)\n",
        "        F_va = prediction.dot(va_matrix)\n",
        "\n",
        "        # dist is a one row vector with size of the test data passed(emotion)\n",
        "        dist = metrics.pairwise.paired_cosine_distances(y_va, F_va)\n",
        "        res = stats.describe(dist)\n",
        "\n",
        "        # print by default (if silent=False)\n",
        "        if not silent:\n",
        "            print('%s\\tmean: %f\\tvariance: %f' % (name, res.mean, res.variance))\n",
        "\n",
        "        return {\n",
        "            'distances': dist,\n",
        "            'dist_stat': res\n",
        "        }\n",
        "\n",
        "    def evaluate_class(cls, predictions, target, target2=None, silent=False):\n",
        "        \"\"\" Compute only the predicted class \"\"\"\n",
        "        p_2_annotation = dict()\n",
        "\n",
        "        precision_recall_fscore_support = [\n",
        "            (pair[0], pair[1].mean()) for pair in zip(\n",
        "                ['precision', 'recall', 'f1', 'support'],\n",
        "                metrics.precision_recall_fscore_support(target, predictions)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        metrics.precision_recall_fscore_support(target, predictions)\n",
        "\n",
        "        # confusion matrix\n",
        "        le = LabelEncoder()\n",
        "        target_le = le.fit_transform(target)\n",
        "        predictions_le = le.transform(predictions)\n",
        "        cm = metrics.confusion_matrix(target_le, predictions_le)\n",
        "\n",
        "        # prediction if two annotations are given on test data\n",
        "        if target2:\n",
        "            p_2_annotation = pd.DataFrame(\n",
        "                [(pred, pred in set([t1,t2])) for pred, t1, t2 in zip(predictions, target, target2)],\n",
        "                columns=['emo','success']\n",
        "            ).groupby('emo').apply(lambda emo: emo.success.sum()/ len(emo.success)).to_dict()\n",
        "\n",
        "        if not silent:\n",
        "            print(\"Default Classification report\")\n",
        "            print(metrics.classification_report(target, predictions))\n",
        "\n",
        "            # print if target2 was provided\n",
        "            if len(p_2_annotation) > 0:\n",
        "                print('\\nPrecision on 2 annotations:')\n",
        "                for emo in p_2_annotation:\n",
        "                    print(\"%s: %.2f\" % (emo, p_2_annotation[emo]))\n",
        "\n",
        "            # print accuracies, precision, recall, and f1\n",
        "            print('\\nAccuracy:')\n",
        "            print(metrics.accuracy_score(target, predictions))\n",
        "            print(\"Correct Predictions: \", metrics.accuracy_score(target, predictions,normalize=False))\n",
        "            for to_print in precision_recall_fscore_support[:3]:\n",
        "                print( \"%s: %.2f\" % to_print )\n",
        "\n",
        "            # normalizing the values of the consfusion matrix\n",
        "            print('\\nconfusion matrix\\n %s' % cm)\n",
        "            print('(row=expected, col=predicted)')\n",
        "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cls.plot_confusion_matrix(cm_normalized, le.classes_, 'Confusion matrix Normalized')\n",
        "\n",
        "        return {\n",
        "            'precision_recall_fscore_support': precision_recall_fscore_support,\n",
        "            'accuracy': metrics.accuracy_score(target, predictions),\n",
        "            'p_2_annotation': p_2_annotation,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "    def predict_class(cls, X_train, y_train, X_test, y_test,\n",
        "                      pipeline, silent=False, target2=None):\n",
        "        \"\"\" Predicted class,then run some performance evaluation \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict(X_test)\n",
        "        print(\"predictions computed....\")\n",
        "        return cls.evaluate_class(predictions, y_test, target2, silent)\n",
        "\n",
        "    def evaluate_prob(cls, prediction, target_rank, target_class, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Evaluate through probability \"\"\"\n",
        "        # Run normal class evaluator\n",
        "        predict_class = binarizer.classes_[prediction.argmax(axis=1)]\n",
        "        class_eval = cls.evaluate_class(predict_class, target_class, target2, silent)\n",
        "\n",
        "        if not silent:\n",
        "            print('\\n - First Emotion Classification Metrics -')\n",
        "            print('\\n - Multiple Emotion rank Metrics -')\n",
        "            print('VA Cosine Distance')\n",
        "\n",
        "        classes_dist = [\n",
        "            (\n",
        "                emo,\n",
        "                cls.va_dist(\n",
        "                    prediction[np.array(target_class) == emo],\n",
        "                    target_rank[np.array(target_class) == emo],\n",
        "                    va_df,\n",
        "                    binarizer,\n",
        "                    emo,\n",
        "                    silent)\n",
        "                ) for emo in binarizer.classes_\n",
        "        ]\n",
        "        avg_dist = cls.va_dist(prediction, target_rank, va_df, binarizer, 'avg', silent)\n",
        "\n",
        "        coverage_error = metrics.coverage_error(target_rank, prediction)\n",
        "        average_precision_score = metrics.average_precision_score(target_rank, prediction)\n",
        "        label_ranking_average_precision_score = metrics.label_ranking_average_precision_score(target_rank, prediction)\n",
        "        label_ranking_loss = metrics.label_ranking_loss(target_rank, prediction)\n",
        "\n",
        "        # recall at 2\n",
        "        # obtain top two predictions\n",
        "        top2_pred = [set([binarizer.classes_[i[0]], binarizer.classes_[i[1]]]) for i in (prediction.argsort(axis=1).T[-2:].T)]\n",
        "        recall_at_2 = pd.DataFrame(\n",
        "            [\n",
        "            t in p for t, p in zip(target_class, top2_pred)\n",
        "            ], index=target_class, columns=['recall@2']).groupby(level=0).apply(lambda emo: emo.sum()/len(emo))\n",
        "\n",
        "        # combine target into sets\n",
        "        if target2:\n",
        "            union_target = [set(t) for t in zip(target_class, target2)]\n",
        "        else:\n",
        "            union_target = [set(t) for t in zip(target_class)]\n",
        "\n",
        "        # precision at k\n",
        "        top_k_pred = [\n",
        "            [set([binarizer.classes_[i] for i in i_list]) for i_list in (prediction.argsort(axis=1).T[-i:].T)]\n",
        "            for i in range(2, len(binarizer.classes_)+1)]\n",
        "        precision_at_k = [\n",
        "            ('p@' + str(k+2), np.array([len(t & p)/(k+2) for t, p in zip(union_target, top_k_pred[k])]).mean())\n",
        "            for k in range(len(top_k_pred))]\n",
        "\n",
        "        # do this if silent= False\n",
        "        if not silent:\n",
        "            print('\\n')\n",
        "            print(recall_at_2)\n",
        "            print('\\n')\n",
        "            print('p@k')\n",
        "            for pk in precision_at_k:\n",
        "                print(pk[0] + ':\\t' + str(pk[1]))\n",
        "            print('\\ncoverage_error: %f' % coverage_error)\n",
        "            print('average_precision_score: %f' % average_precision_score)\n",
        "            print('label_ranking_average_precision_score: %f' % label_ranking_average_precision_score)\n",
        "            print('label_ranking_loss: %f' % label_ranking_loss)\n",
        "\n",
        "        return {\n",
        "            'class_eval': class_eval,\n",
        "            'recall_at_2': recall_at_2.to_dict(),\n",
        "            'precision_at_2': precision_at_k,\n",
        "            'classes_dist': classes_dist,\n",
        "            'avg_dist': avg_dist,\n",
        "            'coverage_error': coverage_error,\n",
        "            'average_precision_score': average_precision_score,\n",
        "            'label_ranking_average_precision_score': label_ranking_average_precision_score,\n",
        "            'label_ranking_loss': label_ranking_loss\n",
        "        }\n",
        "\n",
        "\n",
        "    def predict_prob(cls, X_train, y_train, X_test, y_test, label_test, pipeline, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Output predcations based on training and labels \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict_proba(X_test)\n",
        "        pred_to_mlb = [np.where(pipeline.classes_ == emo)[0][0] for emo in binarizer.classes_.tolist()]\n",
        "        return cls.evaluate_prob(predictions[:,pred_to_mlb], y_test, label_test, binarizer, va_df, silent, target2)\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(cls, cm, my_tags, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        \"\"\" Plotting the confusion_matrix\"\"\"\n",
        "        plt.rc('figure', figsize=(4, 4), dpi=100)\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(my_tags))\n",
        "        target_names = my_tags\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "        \n",
        "        # add normalized values inside the Confusion matrix\n",
        "        fmt = '.2f'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUWz-LBSuDz",
        "outputId": "0c3de2cd-0e2d-49d1-e91c-1042bea203d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "source": [
        "evaluator = Evaluate()\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for p in all_predictions:\n",
        "    for sub_p in p:\n",
        "        final_predictions.append(sub_p.cpu().detach().numpy())\n",
        "        \n",
        "predictions = [np.argmax(p).item() for p in final_predictions]\n",
        "targets = [np.argmax(t).item() for t in y_raw]\n",
        "correct_predictions = float(np.sum(predictions == targets))\n",
        "\n",
        "# predictions\n",
        "predictions_human_readable = ((x_raw, predictions))\n",
        "# actual targets\n",
        "target_human_readable = ((x_raw,  targets))\n",
        "\n",
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
        "\n",
        "# convert results into dataframe\n",
        "model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"emotion\"])\n",
        "test = pd.DataFrame(target_human_readable[1], columns=[\"emotion\"])\n",
        "\n",
        "model_test_result.emotion = model_test_result.emotion.map(lambda x: emotion_dict[int(float(x))])\n",
        "test.emotion = test.emotion.map(lambda x: emotion_dict[int(x)])\n",
        "\n",
        "evaluator.evaluate_class(model_test_result.emotion, test.emotion );"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.95      0.89      0.92       703\n",
            "        fear       0.85      0.91      0.88       580\n",
            "         joy       0.95      0.95      0.95      1689\n",
            "        love       0.84      0.84      0.84       420\n",
            "     sadness       0.96      0.97      0.96      1431\n",
            "    surprise       0.82      0.74      0.78       169\n",
            "\n",
            "    accuracy                           0.93      4992\n",
            "   macro avg       0.89      0.88      0.89      4992\n",
            "weighted avg       0.93      0.93      0.93      4992\n",
            "\n",
            "\n",
            "Accuracy:\n",
            "0.9254807692307693\n",
            "Correct Predictions:  4620\n",
            "precision: 0.89\n",
            "recall: 0.88\n",
            "f1: 0.89\n",
            "\n",
            "confusion matrix\n",
            " [[ 624   37   10    1   31    0]\n",
            " [  13  529    1    1   20   16]\n",
            " [   2    8 1601   61    7   10]\n",
            " [   1    0   63  354    2    0]\n",
            " [  16   11   11    5 1387    1]\n",
            " [   0   34    8    1    1  125]]\n",
            "(row=expected, col=predicted)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAGFCAYAAADJmEVqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKnED1pMdZ4+9yrjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTCznkUGSuD3"
      },
      "source": [
        "## Final Words\n",
        "You have learned how to perform neural-based emotion recognition using RNNs. There are many things you can do after you have completed this tutorial. You can attempt the exercises outlined in the \"Outline\" section of this notebook. You can also try other types of neural architectures such as LSTMs, Bi-LSTMS, attentions models, and CNNs. In addition, you can also store the models and conduct transfer learning to other emotion-related tasks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbkPHgFSuD3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLfZrr2oSuD4"
      },
      "source": [
        "## References\n",
        "- [Deep Learning for NLP](https://docs.google.com/presentation/d/1cf2H1qMvP1rdKUF5000ifOIRv1_b0bvj0ZTVL7-RaVE/edit?usp=sharing)\n",
        "- [PyTorch Autograd Tutorial](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n",
        "- [A Simple Neural Network from Scratch with PyTorch and Google Colab](https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0)\n",
        "- [Building RNNs is Fun with PyTorch and Google Colab](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79?source=collection_home---4------2---------------------)\n",
        "- [Deep Learning for NLP: An Overview of Recent Trends](https://medium.com/dair-ai/deep-learning-for-nlp-an-overview-of-recent-trends-d0d8f40a776d)"
      ]
    }
  ]
}